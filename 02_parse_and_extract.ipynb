{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acda130b",
   "metadata": {},
   "source": [
    "# Step 2: Parse HTML and Extract Book Data\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Parse the downloaded HTML files using BeautifulSoup\n",
    "2. Extract book information (title, price, rating)\n",
    "3. Combine data from all 50 pages\n",
    "4. Export the data to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19aa8f0",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "First, let's install BeautifulSoup4 and lxml for HTML parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1d775a-f161-4aab-9c91-351d24c5f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (6.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d84f4",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import BeautifulSoup for HTML parsing and pandas for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80791988-c8c2-45e5-b594-1a0da80f1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821a0bb",
   "metadata": {},
   "source": [
    "## Extract Data from All Pages\n",
    "\n",
    "Now we'll loop through all 50 downloaded HTML files and extract book information from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f186b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data from page 1\n",
      "Extracted data from page 2\n",
      "Extracted data from page 3\n",
      "Extracted data from page 4\n",
      "Extracted data from page 5\n",
      "Extracted data from page 6\n",
      "Extracted data from page 7\n",
      "Extracted data from page 8\n",
      "Extracted data from page 9\n",
      "Extracted data from page 10\n",
      "Extracted data from page 11\n",
      "Extracted data from page 12\n",
      "Extracted data from page 13\n",
      "Extracted data from page 14\n",
      "Extracted data from page 15\n",
      "Extracted data from page 16\n",
      "Extracted data from page 17\n",
      "Extracted data from page 18\n",
      "Extracted data from page 19\n",
      "Extracted data from page 20\n",
      "Extracted data from page 21\n",
      "Extracted data from page 22\n",
      "Extracted data from page 23\n",
      "Extracted data from page 24\n",
      "Extracted data from page 25\n",
      "Extracted data from page 26\n",
      "Extracted data from page 27\n",
      "Extracted data from page 28\n",
      "Extracted data from page 29\n",
      "Extracted data from page 30\n",
      "Extracted data from page 31\n",
      "Extracted data from page 32\n",
      "Extracted data from page 33\n",
      "Extracted data from page 34\n",
      "Extracted data from page 35\n",
      "Extracted data from page 36\n",
      "Extracted data from page 37\n",
      "Extracted data from page 38\n",
      "Extracted data from page 39\n",
      "Extracted data from page 40\n",
      "Extracted data from page 41\n",
      "Extracted data from page 42\n",
      "Extracted data from page 43\n",
      "Extracted data from page 44\n",
      "Extracted data from page 45\n",
      "Extracted data from page 46\n",
      "Extracted data from page 47\n",
      "Extracted data from page 48\n",
      "Extracted data from page 49\n",
      "Extracted data from page 50\n",
      "\n",
      "Total books extracted: 1000\n"
     ]
    }
   ],
   "source": [
    "# List to store all book data\n",
    "all_books = []\n",
    "\n",
    "# Loop through all 50 pages\n",
    "for page_num in range(1, 51):\n",
    "    try:\n",
    "        # Read the HTML file\n",
    "        with open(f\"htmls/page{page_num}.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        \n",
    "        # Find all book articles on the page\n",
    "        articles = soup.select(\"article.product_pod\")\n",
    "        \n",
    "        # Extract data from each book\n",
    "        for article in articles:\n",
    "            # Get book title\n",
    "            title = article.find(\"h3\").find(\"a\")[\"title\"]\n",
    "            \n",
    "            # Get price (remove the £ symbol)\n",
    "            price = article.select_one(\"p.price_color\").text.split(\"£\")[1]\n",
    "            \n",
    "            # Get rating\n",
    "            rating_element = article.select_one(\"p.star-rating\")\n",
    "            rating = rating_element['class'][1]\n",
    "            \n",
    "            # Add to our list\n",
    "            all_books.append([title, price, rating])\n",
    "        \n",
    "        print(f\"Extracted data from page {page_num}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_num}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal books extracted: {len(all_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd4a416-9e62-4089-b800-0f49d5feb830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame created with 1000 books\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with appropriate column names\n",
    "df = pd.DataFrame(all_books, columns=[\"Book Title\", \"Price\", \"Rating\"])\n",
    "print(f\"DataFrame created with {len(df)} books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1c59f",
   "metadata": {},
   "source": [
    "## Create DataFrame\n",
    "\n",
    "Convert our list of books into a pandas DataFrame for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77095f5e-a8a2-4854-b2e9-f02d49d54850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>51.77</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>54.23</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>22.65</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>33.34</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>22.60</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>52.15</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Book Title  Price Rating\n",
       "0                               A Light in the Attic  51.77  Three\n",
       "1                                 Tipping the Velvet  53.74    One\n",
       "2                                         Soumission  50.10    One\n",
       "3                                      Sharp Objects  47.82   Four\n",
       "4              Sapiens: A Brief History of Humankind  54.23   Five\n",
       "5                                    The Requiem Red  22.65    One\n",
       "6  The Dirty Little Secrets of Getting Your Dream...  33.34   Four\n",
       "7  The Coming Woman: A Novel Based on the Life of...  17.93  Three\n",
       "8  The Boys in the Boat: Nine Americans and Their...  22.60   Four\n",
       "9                                    The Black Maria  52.15    One"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7aafd8",
   "metadata": {},
   "source": [
    "## Preview the Data\n",
    "\n",
    "Let's take a look at the first few rows of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76847bf7-2d3a-432d-96a8-3c2226c5be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to data.csv!\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV file\n",
    "df.to_csv(\"data.csv\", index=False)\n",
    "print(\"Data successfully saved to data.csv!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be283a03",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ Successfully scraped and extracted book data from all 50 pages!\n",
    "\n",
    "You can now use `data.csv` for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87bf97",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "\n",
    "Save our extracted data to a CSV file for future use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
