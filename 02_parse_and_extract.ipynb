{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acda130b",
   "metadata": {},
   "source": [
    "# Step 2: Parse HTML and Extract Book Data\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Parse the downloaded HTML files using BeautifulSoup\n",
    "2. Extract book information (title, price, rating)\n",
    "3. Combine data from all 50 pages\n",
    "4. Export the data to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19aa8f0",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "First, let's install BeautifulSoup4 and lxml for HTML parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d775a-f161-4aab-9c91-351d24c5f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (4.14.2)\n",
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sthak\\anaconda3\\envs\\krienv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Downloading lxml-6.0.2-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 25.5 MB/s  0:00:00\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-6.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718d84f4",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import BeautifulSoup for HTML parsing and pandas for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80791988-c8c2-45e5-b594-1a0da80f1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821a0bb",
   "metadata": {},
   "source": [
    "## Extract Data from All Pages\n",
    "\n",
    "Now we'll loop through all 50 downloaded HTML files and extract book information from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f186b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all book data\n",
    "all_books = []\n",
    "\n",
    "# Loop through all 50 pages\n",
    "for page_num in range(1, 51):\n",
    "    try:\n",
    "        # Read the HTML file\n",
    "        with open(f\"htmls/page{page_num}.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(content, \"html.parser\")\n",
    "        \n",
    "        # Find all book articles on the page\n",
    "        articles = soup.select(\"article.product_pod\")\n",
    "        \n",
    "        # Extract data from each book\n",
    "        for article in articles:\n",
    "            # Get book title\n",
    "            title = article.find(\"h3\").find(\"a\")[\"title\"]\n",
    "            \n",
    "            # Get price (remove the £ symbol)\n",
    "            price = article.select_one(\"p.price_color\").text.split(\"£\")[1]\n",
    "            \n",
    "            # Get rating\n",
    "            rating_element = article.select_one(\"p.star-rating\")\n",
    "            rating = rating_element['class'][1]\n",
    "            \n",
    "            # Add to our list\n",
    "            all_books.append([title, price, rating])\n",
    "        \n",
    "        print(f\"Extracted data from page {page_num}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing page {page_num}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal books extracted: {len(all_books)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4a416-9e62-4089-b800-0f49d5feb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with appropriate column names\n",
    "df = pd.DataFrame(all_books, columns=[\"Book Title\", \"Price\", \"Rating\"])\n",
    "print(f\"DataFrame created with {len(df)} books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1c59f",
   "metadata": {},
   "source": [
    "## Create DataFrame\n",
    "\n",
    "Convert our list of books into a pandas DataFrame for easier manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77095f5e-a8a2-4854-b2e9-f02d49d54850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>51.77</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>53.74</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>50.10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>47.82</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>54.23</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>22.65</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>33.34</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>17.93</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>22.60</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>52.15</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>13.99</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>20.66</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>17.46</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>52.29</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>35.02</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>57.25</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>23.88</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>37.59</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>51.33</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>45.17</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Title  Price Rating\n",
       "0                                A Light in the Attic  51.77  Three\n",
       "1                                  Tipping the Velvet  53.74    One\n",
       "2                                          Soumission  50.10    One\n",
       "3                                       Sharp Objects  47.82   Four\n",
       "4               Sapiens: A Brief History of Humankind  54.23   Five\n",
       "5                                     The Requiem Red  22.65    One\n",
       "6   The Dirty Little Secrets of Getting Your Dream...  33.34   Four\n",
       "7   The Coming Woman: A Novel Based on the Life of...  17.93  Three\n",
       "8   The Boys in the Boat: Nine Americans and Their...  22.60   Four\n",
       "9                                     The Black Maria  52.15    One\n",
       "10     Starving Hearts (Triangular Trade Trilogy, #1)  13.99    Two\n",
       "11                              Shakespeare's Sonnets  20.66   Four\n",
       "12                                        Set Me Free  17.46   Five\n",
       "13  Scott Pilgrim's Precious Little Life (Scott Pi...  52.29   Five\n",
       "14                          Rip it Up and Start Again  35.02   Five\n",
       "15  Our Band Could Be Your Life: Scenes from the A...  57.25  Three\n",
       "16                                               Olio  23.88    One\n",
       "17  Mesaerion: The Best Science Fiction Stories 18...  37.59    One\n",
       "18                       Libertarianism for Beginners  51.33    Two\n",
       "19                            It's Only the Himalayas  45.17    Two"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7aafd8",
   "metadata": {},
   "source": [
    "## Preview the Data\n",
    "\n",
    "Let's take a look at the first few rows of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76847bf7-2d3a-432d-96a8-3c2226c5be06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV file\n",
    "df.to_csv(\"data.csv\", index=False)\n",
    "print(\"Data successfully saved to data.csv!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be283a03",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ Successfully scraped and extracted book data from all 50 pages!\n",
    "\n",
    "You can now use `data.csv` for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87bf97",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "\n",
    "Save our extracted data to a CSV file for future use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
